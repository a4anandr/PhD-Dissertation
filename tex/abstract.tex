% Write in only the text of your abstract, all the extra heading jargon is automatically taken care of
\begin{abstract}
It is known that the gradient to the solution of a particular version of the Poisson's equation plays a crucial role in the feedback particle filter (FPF), and it was recently discovered that the same object can be used to reduce variance in common MCMC algorithms. In the feedback particle filter, the gradient to the solution has interpretation as the innovations gain. In MCMC algorithms, it appears in the objective function to minimize the asymptotic variance of the mean estimates; optimal control variates can be computed using the approximation.

Approximate solutions are obtained using a new formulation of the \textit{differential} TD-learning algorithm. This requires the choice of a parameterized family of functions within which the approximation lies. We consider two cases: a finite dimensional family of functions, and a reproducing kernel Hilbert space (RKHS). In the RKHS setting, the objective function is represented in the form of an empirical risk minimization problem that allows us to apply a recent variation of RKHS theory to find the optimal approximation. Both applications are discussed in detail and illustrated with numerical experiments.

\end{abstract}
